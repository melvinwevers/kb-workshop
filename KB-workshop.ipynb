{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mining Delpher Data</h2>\n",
    "<h3>Harvest, Clean and Analyse Large Amounts of Digitised Text</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>When analysing sources of the National Library of the Netherlands (KB), researchers often use Delpher, the online gateway to more than 10 million pages of historical text (newspapers, books,journals & radio bulletins), mostly in Dutch. Delpher allows you to search and browse all documents in full text, making it a good resource for close reading. However, when you want to analyse large amounts of data to do distant reading, the KB allows researchers access to both the digital images, metadata, and full text in bulk via KB’s Dataservices & API’s, as well as additional data such as the Medieval Illuminated Manuscripts and the Dutch Digital Parliamentary Papers. </p>\n",
    "\n",
    "<p>To successfully harvest this data and subsequently clean and analyse it, you need knowledge about:\n",
    "\n",
    "<ul>\n",
    "<li> the KB’s data formats and infrastructure</li>\n",
    "<li> tools to clean the data and subsequently</li>\n",
    "<li> tools to analyse the data.</li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Jupyter Notebook Tips</h3>\n",
    "<ul>\n",
    "<li>New cells are created with the <b>Plus</b> button in the toolbar. When not editing, this can be done by pressing ‘b’ on your keyboard.</li>\n",
    "<li>New cells are “code” cells by default, but can be changed to “Markdown” (a type of text input) in a dropdown menu on the toolbar. In edit mode, you can paste in code from this lesson or type it yourself.</li>\n",
    "<li>Switching a cell to edit mode is done by pressing Enter.</li>\n",
    "<li>Running a cell is done by clicking Play in the toolbar, or with Shift + Enter.</li>\n",
    "<li>We use two types of cells: Markdown (for text) and Code (for code blocks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Libraries and settings</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv #to work with csv files\n",
    "import pandas as pd #for data analysis\n",
    "import numpy as np #for scientific computing\n",
    "import requests #for html requests \n",
    "from lxml import etree #for browsing xml structures\n",
    "\n",
    "SRU_BASE_URL = 'http://jsru.kb.nl/sru/sru?' #the url for the KB's sru service\n",
    "MAX_RECORDS = 1000 #the number of records queried at a time \n",
    "pd.set_option('display.max_colwidth', -1) #this options show the full cell contents of the pandas output. \n",
    "#this option shows graphs within Jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Harvest Function</h2>\n",
    "\n",
    "The following function is used to communicate with the SRU service, download collection of texts with the fields 'text', 'date', and 'title'. The download is stored as a tsv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jsru_query(collection, cql, filename):\n",
    "    '''\n",
    "    Query jSRU to obtain from collection context (text), date and title fields,\n",
    "    write results to tab separated CSV file.\n",
    "    '''\n",
    "\n",
    "    start_record = 1\n",
    "\n",
    "    request_payload = {\n",
    "        'operation': 'searchRetrieve',\n",
    "        'x-collection': collection,\n",
    "        'x-fields': 'content',\n",
    "        'maximumRecords': MAX_RECORDS,\n",
    "        'startRecord': start_record,\n",
    "        'query': cql\n",
    "    }\n",
    "\n",
    "    sru_response = requests.get(SRU_BASE_URL, params=request_payload)\n",
    "    sru_tree = etree.fromstring(sru_response.content)\n",
    "\n",
    "    num_records = sru_tree.find('{http://www.loc.gov/zing/srw/}numberOfRecords')\n",
    "    num_records = int(num_records.text)\n",
    "    \n",
    "    csv_writer = csv.writer(open(filename, 'w', newline=''), delimiter='\\t')\n",
    "    csv_writer.writerow(['title', 'date', 'text'])\n",
    "\n",
    "    records_left = (num_records >= 1)\n",
    "    while records_left:\n",
    "        \n",
    "        for record in sru_tree.iter('{http://www.loc.gov/zing/srw/}recordData'):\n",
    "            title = record.find('{http://purl.org/dc/elements/1.1/}title').text\n",
    "            date = record.find('{http://purl.org/dc/elements/1.1/}date').text\n",
    "            text = record.find('content').text\n",
    "\n",
    "            csv_writer.writerow([title, date, text])\n",
    "\n",
    "        records_left=(start_record + MAX_RECORDS <= num_records)\n",
    "        if records_left:\n",
    "            start_record = start_record + MAX_RECORDS\n",
    "            request_payload['startRecord'] = start_record\n",
    "            sru_response = requests.get(SRU_BASE_URL, params=request_payload)\n",
    "            sru_tree = etree.fromstring(sru_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Downloading data from Delpher</h2>\n",
    "\n",
    "<p>Here you can run the function called jsru_query that is defined in the cell above. This function has three parameters.</p> \n",
    "<ol>\n",
    "<li>the collection (ANP)</li>\n",
    "<li>the query (\"verenigde staten\" and nederland not duitsland and date within \"01-01-1971 31-12-1979\"), and \n",
    "<li>the name of the output file (output.tsv).</li>\n",
    "</ol>\n",
    "\n",
    "Make sure to enclose these three parameters with apostrophes. \n",
    "We will now try to rebuild the queries we made during the first part of this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Example Query\n",
    "jsru_query('ANP', \n",
    "           '\"verenigde staten\" and nederland not duitsland and date within \"01-01-1971 31-12-1979\"', \n",
    "           'output.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing downloaded data into Python</h2>\n",
    "<p>Now we will load the tsv into python using a library called Pandas. <br> Pandas is a library that is often used by data scientists. <br> You can read more about Pandas here: https://pandas.pydata.org\n",
    "<br> N.B. A table or spreadsheet is called a dataframe in Pandas. </p>\n",
    "You can find a new cheat sheet here: https://www.dataquest.io/blog/images/cheat-sheets/pandas-cheat-sheet.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the name of your file here as your input here. This should be the same as the name of \n",
    "#the output you defined in the query function\n",
    "#delimiter indicates how the file is separated. Tabs = '\\t', and commas = ','.\n",
    "#df is the default name for a dataframe. You can give this variable any name you prefer. \n",
    "df = pd.read_csv('output.tsv', delimiter='\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this command shows you the first lines of the file. Put a number between the parenthesis to specify and exact number.\n",
    "#Change df.head into df.tail to see what happens\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df) #the len function shows the length of a variable. In this case how many rows in the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if you want to view specific slices of the dataset. Let's say row 5 to 10, you can use the following command.\n",
    "#N.B. the first row is numbered 0 and not 1. \n",
    "df[5:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Datacleaning</h2>\n",
    "<p>As you have seen the text in the cell is not clean. It contains superfluous character and strings. <br>The next section presents some methods to clean the text in the cell. <br>There are many different ways of doing this, these are just a few examples to give you a sense of how Python and Pandas work. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we will store the original dateframe under a new name (df2). \n",
    "#If you use a different name than df in the previous section change this in the code.\n",
    "df2 = df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2['text'] = df2['text'].str.replace('Red.', '') #remove returning text (Red.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2[5:10] #inspect the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if you wan to skip one of these cleaning steps you can put a # in front of the line. \n",
    "#Python will then think that the code is a comment and it will not interpret it.\n",
    "df2['text'] = df2['text'].str.replace('Datum:.', '') #remove returning text (Datum:.)\n",
    "df2['text'] = df2['text'].str.replace('Tijd:.', '') #remove returning text (Tijd:.)\n",
    "df2['text'] = df2['text'].str.replace('Onderwerp:', '') #remove returning text (Onderwerp:)\n",
    "df2['text'] = df2['text'].str.replace('\\n', '') #remove newline (/n) character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['text'] = df2['text'].str.replace('\\d+', '') #remove all digits from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2['text'] = df2['text'].str.findall('\\w{3,}').str.join(' ') #remove words shorter than 4 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['text'].replace('[!\"#%\\'()*+,-/:;<=>?@\\[\\]^_`{|}~’”“′‘\\\\\\]',' ',inplace=True,regex=True) #remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2['text'] = df2['text'].str.lower() #convert all the text into lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is a method you can use to remove articles that contain particular words, in this case 'Egypte' and 'Turkije'\n",
    "to_drop = ['Egypte', 'Turkije'] \n",
    "df2 = df2[~df2['text'].isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#inspect the dataframe after the cleaning. \n",
    "#You can also run df[5:10] in a new cell (with the + sign) to compare the differences. \n",
    "df2[5:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Visualization</h2> \n",
    "<p>In this section, we are going to generate a simple line graph that shows the number of articles over time. We will select different time scales.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2['date'] #show the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['date'] = df2['date'].str.replace(' 00:00:00', '') #re-format date to just show year-month-day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['date'] = pd.to_datetime(df2['date']) #tell Pandas that this column contains date information\n",
    "df2 = df2.set_index(['date']) #set the date column as the index. This makes calculations involving time easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2['text'].groupby(pd.TimeGrouper('12M')).count().plot(kind='line')\n",
    "#also try this with D, W, M, 6M, 12M "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#You can create new dataframes that only contain a slice of the data based on their date. \n",
    "#Change the names of the variables 'df1970-1971' and 'df1975-1979' and the way they are sliced'\n",
    "df1970_1971 = df2['1970':'1971']\n",
    "df1975_1979 = df2['1975':'1979']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Output data</h2>\n",
    "<p>In the next part of this workshop, we will work with raw text data. For this reason, we will export only the text column of the dataframe as one larger text-file.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#give the .txt file a name you prefer\n",
    "#we leave out the index column and the headers and only select the column 'text'\n",
    "#you can also change df into the name of the slice you defined in the previous step. For instance, df1970_1971.\n",
    "df2['text'].to_csv(\"raw_text_clean.txt\", sep=' ', index=False, header=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we will also output the text that was not cleaned. Save this using a different output name\n",
    "df['text'].to_csv(\"raw_text.txt\", sep=' ', index=False, header=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
