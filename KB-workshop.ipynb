{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mining Delpher Data</h2>\n",
    "<h3>Harvest, Clean and Analyse large amounts of digitised text</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>When analysing sources of the National Library of the Netherlands (KB), researchers often use Delpher, the online gateway to more than 10 million pages of historical text (newspapers, books,journals & radio bulletins), mostly in Dutch. Delpher allows you to search and browse all documents in full text, making it a good resource for close reading. However, when you want to analyse large amounts of data to do distant reading, the KB allows researchers access to both the digital images, metadata, and full text in bulk via KB’s Dataservices & API’s, as well as additional data such as the Medieval Illuminated Manuscripts and the Dutch Digital Parliamentary Papers. To successfully harvest this data and subsequently clean and analyse it, you need knowledge about:\n",
    "\n",
    "<ul>\n",
    "<li> the KB’s data formats and infrastructure,</li>\n",
    "<li> tools to clean the data and subsequently</li>\n",
    "<li> tools to analyse the data.</li>\n",
    "</ul>\n",
    "\n",
    "<p>During this workshop, you will get a hands-on experience and guidance on all three steps. Experts of the KB (René Voorburg, Steven Claeyssens and Martijn Kleppe) will first guide you through KB’s metadata and available datasets. Then a PhD researcher of Utrecht University (Melvin Wevers) will show you which tools are available to clean the data and will assist you in making the first analyses.</p>\n",
    "\n",
    "<p>During the first part of the workshop you will be guided through a number of exercises and all use the same dataset. During the second part you will be able to make a start with freely collecting and working with a selection of KB datasets that best fits your research interest, all under guidance of KB experts.</p>\n",
    "\n",
    "<p>This workshop is aimed specifically at beginning users that have an interest in the KB Data. We assume no prior experience working with KB (meta)data nor any other significant technical knowledge or skills, such as programming skills, although basic computer skills are expected. The workshop will be in English. All data that we will work with, will be in Dutch.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Jupyter Notebook Tips</h3>\n",
    "<ul>\n",
    "<li>New cells are created with the Plus button in the toolbar. When not editing, this can be done by pressing ‘b’ on your keyboard.</li>\n",
    "<li>New cells are “code” cells by default, but can be changed to “Markdown” (a type of text input) in a dropdown menu on the toolbar. In edit mode, you can paste in code from this lesson or type it yourself.</li>\n",
    "<li>Switching a cell to edit mode is done by pressing Enter.</li>\n",
    "<li>Running a cell is done by clicking Play in the toolbar, or with Ctrl+Enter (Cmd+Return on Mac OS).</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "SRU_BASE_URL = 'http://jsru.kb.nl/sru/sru?'\n",
    "MAX_RECORDS = 1000\n",
    "pd.set_option('display.max_colwidth', -1) #this options show the full cell contents of the pandas output. \n",
    "#this option shows graphs within Jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Harvest Function</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jsru_query(collection, cql, filename):\n",
    "    '''\n",
    "    Query jSRU to obtain from collection context (text), date and title fields,\n",
    "    write results to tab separated CSV file.\n",
    "    '''\n",
    "\n",
    "    start_record = 1\n",
    "\n",
    "    request_payload = {\n",
    "        'operation': 'searchRetrieve',\n",
    "        'x-collection': collection,\n",
    "        'x-fields': 'content',\n",
    "        'maximumRecords': MAX_RECORDS,\n",
    "        'startRecord': start_record,\n",
    "        'query': cql\n",
    "    }\n",
    "\n",
    "    sru_response = requests.get(SRU_BASE_URL, params=request_payload)\n",
    "    sru_tree = etree.fromstring(sru_response.content)\n",
    "\n",
    "    num_records = sru_tree.find('{http://www.loc.gov/zing/srw/}numberOfRecords')\n",
    "    num_records = int(num_records.text)\n",
    "    \n",
    "    csv_writer = csv.writer(open(filename, 'w', newline=''), delimiter='\\t')\n",
    "    csv_writer.writerow(['title', 'date', 'text'])\n",
    "\n",
    "    records_left = (num_records >= 1)\n",
    "    while records_left:\n",
    "        \n",
    "        for record in sru_tree.iter('{http://www.loc.gov/zing/srw/}recordData'):\n",
    "            title = record.find('{http://purl.org/dc/elements/1.1/}title').text\n",
    "            date = record.find('{http://purl.org/dc/elements/1.1/}date').text\n",
    "            text = record.find('content').text\n",
    "\n",
    "            csv_writer.writerow([title, date, text])\n",
    "\n",
    "        records_left=(start_record + MAX_RECORDS <= num_records)\n",
    "        if records_left:\n",
    "            start_record = start_record + MAX_RECORDS\n",
    "            request_payload['startRecord'] = start_record\n",
    "            sru_response = requests.get(SRU_BASE_URL, params=request_payload)\n",
    "            sru_tree = etree.fromstring(sru_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Downloading data from Delpher</h2>\n",
    "\n",
    "<p>Here you can run the function called jsru_query that is defined in the cell above. This function has three parameters.</p>\n",
    "<ol>\n",
    "<li>the collection (ANP)</li>\n",
    "<li>the query (\"verenigde staten\" and nederland not duitsland and date within \"01-01-1971 31-12-1979\"), and \n",
    "<li>the name of the output file (output.csv).</li>\n",
    "</ol>\n",
    "\n",
    "Make sure to enclose these three parameters with apostrophes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Example Query\n",
    "jsru_query('ANP', \n",
    "           '\"verenigde staten\" and nederland not duitsland and date within \"01-01-1971 31-12-1979\"', \n",
    "           'output.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing downloaded data into Python</h2>\n",
    "<p>Now we will load the tsv into python using a library called Pandas. <br> Pandas is a library that is often used by data scientists. <br> You can read more about Pandas here: https://pandas.pydata.org\n",
    "<br> N.B. A table or spreadsheet is called a dataframe in Pandas. </p>\n",
    "You can find a new cheat sheet here: https://www.dataquest.io/blog/images/cheat-sheets/pandas-cheat-sheet.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the name of your file here as your input here. This should be the same as the name of \n",
    "#the output you defined in the query function\n",
    "#delimiter indicates how the file is separated. Tabs = '\\t', and commas = ','.\n",
    "#df is the default name for a dataframe. You can give this variable any name you prefer. \n",
    "df = pd.read_csv('output.tsv', delimiter='\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this command shows you the first lines of the file. Put a number between the parenthesis to specify and exact number.\n",
    "#Change df.head into df.tail to see what happens\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df) #the len function shows the length of a variable. In this case how many rows in the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if you want to view specific slices of the dataset. Let's say row 5 to 10, you can use the following command.\n",
    "#N.B. the first row is numbered 0 and not 1. \n",
    "df[5:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Datacleaning</h2>\n",
    "<p>As you have seen the text in the cell is not clean. <br>It contains superfluous character and strings. <br>The next section presents some methods to clean the text in the cell. <br>There are many different ways of doing this, these are just a few examples to give you a sense of how Python and Pandas work. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('Red.', '') #remove returning text (Red.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[5:10] #inspect the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('Datum:.', '') #remove returning text (Datum:.)\n",
    "df['text'] = df['text'].str.replace('Tijd:.', '') #remove returning text (Tijd:.)\n",
    "df['text'] = df['text'].str.replace('Onderwerp:', '') #remove returning text (Onderwerp:)\n",
    "df['text'] = df['text'].str.replace('\\n', '') #remove newline (/n) character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('\\d+', '') #remove all digits from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.findall('\\w{4,}').str.join(' ') #remove words shorter than 4 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['text'].replace('[!\"#%\\'()*+,-/:;<=>?@\\[\\]^_`{|}~’”“′‘\\\\\\]',' ',inplace=True,regex=True) #remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower() #convert all the text into lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is a method you can use to remove articles that contain particular words\n",
    "to_drop = ['Egypte', 'Turkije'] \n",
    "df = df[~df['text'].isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[5:10] #inspect the dataframe looks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Visualization</h2> \n",
    "<p>In this section, we are going to generate a simple line graph that shows the number of articles over time. We will select different time scales.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['date'] #show the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['date'] = df['date'].str.replace(' 00:00:00', '') #re-format date to just show year-month-day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date']) #tell Pandas that this column contains date information\n",
    "df = df.set_index(['date']) #set the date column as the index. This makes calculations involving time easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['text'].groupby(pd.TimeGrouper('M')).count().plot(kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#You can create new dataframes that only contain a slice of the data based on their date. \n",
    "#Change the names of the variables 'df1970-1971' and 'df1975-1979' and the way they are sliced'\n",
    "df1970_1971 = df['1970':'1971']\n",
    "df1975_1979 = df['1975':'1979']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Output data</h2>\n",
    "<p>In the next part of this workshop, we will work with raw text data. For this reason, we will export only the text column of the dataframe as one larger text-file.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#give the .txt file a name you prefer\n",
    "#we leave out the index column and the headers and only select the column 'text'\n",
    "#you can also change df into the name of the slice you defined in the previous step. For instance, df1970_1971.\n",
    "df['text'].to_csv(\"1970-1971.txt\", sep=' ', index=False, header=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
